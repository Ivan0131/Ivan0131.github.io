<!doctype html>



  


<html class="theme-next mist use-motion">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />












  
  
  <link href="/vendors/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/vendors/font-awesome/css/font-awesome.min.css?v=4.4.0" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.0.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="vis2016,netural network,visualization,research," />





  <link rel="alternate" href="/atom.xml" title="Ivan's Blog" type="application/atom+xml" />




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.0.1" />






<meta name="description" content="过去几年，深度神经网络在机器学习方面取得了巨大的成功，在某些任务上甚至超过了人类。然而，神经网络是一个black boxes。与传统机器学习方法相比，它不需要人为地去选择特征。如何理解大规模的神经网络却是件困难的事：神经网络通过训练学到了什么特征。 针对这一问题，大量的科研人员进行了大量的研究及实践。在神经网络以及机器学习领域的会议上，已经出现很多关于人工神经网络的文章，包括最近比较流行的卷积神经">
<meta property="og:type" content="article">
<meta property="og:title" content="人工神经网络可视化--2016年可视化会议">
<meta property="og:url" content="http://yanyuyu.info/2016/09/28/vis-2016-netural-network/index.html">
<meta property="og:site_name" content="Ivan's Blog">
<meta property="og:description" content="过去几年，深度神经网络在机器学习方面取得了巨大的成功，在某些任务上甚至超过了人类。然而，神经网络是一个black boxes。与传统机器学习方法相比，它不需要人为地去选择特征。如何理解大规模的神经网络却是件困难的事：神经网络通过训练学到了什么特征。 针对这一问题，大量的科研人员进行了大量的研究及实践。在神经网络以及机器学习领域的会议上，已经出现很多关于人工神经网络的文章，包括最近比较流行的卷积神经">
<meta property="og:image" content="http://yanyuyu.info/img/vis-2016-netural-network/mnist_projection.png">
<meta property="og:image" content="http://yanyuyu.info/img/vis-2016-netural-network/mnist_activation_projection.png">
<meta property="og:image" content="http://yanyuyu.info/img/vis-2016-netural-network/svhn_before_training_projection.png">
<meta property="og:image" content="http://yanyuyu.info/img/vis-2016-netural-network/svhn_after_training_projection.png">
<meta property="og:image" content="http://yanyuyu.info/img/vis-2016-netural-network/mnist_inter_layer_evolution.png">
<meta property="og:image" content="http://yanyuyu.info/img/vis-2016-netural-network/mnist_inter_epoch_evolution.png">
<meta property="og:image" content="http://yanyuyu.info/img/vis-2016-netural-network/mnist_activation_neuron_projection.png">
<meta property="og:image" content="http://yanyuyu.info/img/vis-2016-netural-network/svhn_neuron_map.png">
<meta property="og:image" content="http://yanyuyu.info/img/vis-2016-netural-network/svhn_activation_projection.png">
<meta property="og:image" content="http://yanyuyu.info/img/vis-2016-netural-network/alexnet1.png">
<meta property="og:image" content="http://yanyuyu.info/img/vis-2016-netural-network/alexnet2.png">
<meta property="og:image" content="http://yanyuyu.info/img/vis-2016-netural-network/y_system_overview.png">
<meta property="og:image" content="http://yanyuyu.info/img/vis-2016-netural-network/activations_151_1.png">
<meta property="og:image" content="http://yanyuyu.info/img/vis-2016-netural-network/activations_151_2.png">
<meta property="og:image" content="http://yanyuyu.info/img/vis-2016-netural-network/activation_max.png">
<meta property="og:image" content="http://yanyuyu.info/img/vis-2016-netural-network/activation_max_unit.png">
<meta property="og:image" content="http://yanyuyu.info/img/vis-2016-netural-network/cnnvis_system.png">
<meta property="og:image" content="http://yanyuyu.info/img/vis-2016-netural-network/cnnvis_pipeline.png">
<meta property="og:updated_time" content="2016-09-30T04:36:56.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="人工神经网络可视化--2016年可视化会议">
<meta name="twitter:description" content="过去几年，深度神经网络在机器学习方面取得了巨大的成功，在某些任务上甚至超过了人类。然而，神经网络是一个black boxes。与传统机器学习方法相比，它不需要人为地去选择特征。如何理解大规模的神经网络却是件困难的事：神经网络通过训练学到了什么特征。 针对这一问题，大量的科研人员进行了大量的研究及实践。在神经网络以及机器学习领域的会议上，已经出现很多关于人工神经网络的文章，包括最近比较流行的卷积神经">
<meta name="twitter:image" content="http://yanyuyu.info/img/vis-2016-netural-network/mnist_projection.png">



<script type="text/javascript" id="hexo.configuration">
  var NexT = window.NexT || {};
  var CONFIG = {
    scheme: 'Mist',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: 0,
      author: '博主'
    }
  };
</script>




  <link rel="canonical" href="http://yanyuyu.info/2016/09/28/vis-2016-netural-network/"/>

  <title> 人工神经网络可视化--2016年可视化会议 | Ivan's Blog </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  



  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "//hm.baidu.com/hm.js?a7a9997a965e7ef7e3f42407be8d7f71";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>








  
  
    
  

  <div class="container one-collumn sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">Ivan's Blog</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
  <p class="site-subtitle">sharing what I'm studying</p>
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      

      
    </ul>
  

  
</nav>

 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                人工神经网络可视化--2016年可视化会议
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-09-28T21:43:13+08:00" content="2016-09-28">
              2016-09-28
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/Papers/" itemprop="url" rel="index">
                    <span itemprop="name">Papers</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2016/09/28/vis-2016-netural-network/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2016/09/28/vis-2016-netural-network/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>过去几年，深度神经网络在机器学习方面取得了巨大的成功，在某些任务上甚至超过了人类。然而，神经网络是一个black boxes。与传统机器学习方法相比，它不需要人为地去选择特征。如何理解大规模的神经网络却是件困难的事：神经网络通过训练学到了什么特征。 针对这一问题，大量的科研人员进行了大量的研究及实践。在神经网络以及机器学习领域的会议上，已经出现很多关于人工神经网络的文章，包括最近比较流行的卷积神经网络（Convolutional neural networks， CNN）和循环神经网络（Recurrent neural networks, RNN）。今年在Vis的录用文章中出现了两篇关于神经网络可视化的文章。这说明可视化领域的人也开始关注神经网络，并想通过可视化方法帮助人们去理解神经网络，打开神经网络这个黑盒子。</p>
<!--在Vis上出现的最早的神经网络的文章应该是Kwan-Liu Ma老师2005的Opening the Black Box — Data Driven Visualization of Neural Networks（就目前我调研就相关论文来看，可能有错误）。文中使用的是最简单的三层B神P经网络，使用数据驱动的方式，使用节点连接图展示可视化神经网络。但是当网络变得复杂时，这种可视化形式会造成可视化混乱。用户无法通过如此复杂的节点连接图去理解神经网络。 随着神经网络越来越复杂，单层神经元及网络层次也越来越多，这使得神经网络的可视化变得越来越困难。今年的两个文章主要是针对卷积神经网络在图像数据集上的可视化。下面主要介绍这两篇文章。-->
<h2 id="Visualizing-the-Hidden-Activity-of-Artificial-Neural-Networks"><a href="#Visualizing-the-Hidden-Activity-of-Artificial-Neural-Networks" class="headerlink" title="Visualizing the Hidden Activity of Artificial Neural Networks"></a>Visualizing the Hidden Activity of Artificial Neural Networks</h2><p>这篇论文主要使用降维的方法可视化神经网络学到的数据表示和神经元间的关系。文章主要使用Multilayer perceptrons和Convolutional neural networks这两个神经网络作为例子，使用的数据包括MNIST dataset，SVHN dataset和CIFAR-10 dataset。</p>
<center><br><img src="/img/vis-2016-netural-network/mnist_projection.png" alt="图1 Projection of observations, MNIST test subset(NH: 89.12%)." title="Projection of observations, MNIST test subset."><br></center><br><center><br><img src="/img/vis-2016-netural-network/mnist_activation_projection.png" alt="图2 Projection of the last MLP hidden layer activations, MNIST test subset. a) Before training (NH: 83.78%). b) After training (NH: 98.36%, AC: 99.15%). Inset shows classification of visual outliers." title="Projection of the last MLP hidden layer activations, MNIST test subset."><br></center><br>图1展示了MNIST数据集中10个数字类别直接使用t-SNE降维后的结果。从图中可以看出，对于MNIST数据集，直接降维已经可以较好得把类别区分开了。所以在原来的数据表示上直接使用分类器可以得到较好的结果。在这里，作者使用neighborhood hit (NH)来度量降维后各个类别的区分程度。给定一个k的值，NH表示在相邻k个点中属于同一类的点所占的比例。这里直接降维后NH值为89.12%。<br>图2是为了说明神经网络对于特征的提取作用。MLP最后一层输出层相当于一个multinomial logistic regression。所以神经网络相对于multinomial logistic regression，区别在于之前的隐藏层对于特征的提取。所以图2展示了训练先后神经网络提取得到的特征。图2(b)与图2(a)相比，我们发现训练后的神经网络提取得到的特征可以更好的将各个类别分离。<br><br><center><br><img src="/img/vis-2016-netural-network/svhn_before_training_projection.png" alt="图3 Projection of the last MLP hidden layer activations before training, SVHN test subset (NH: 20.94%). Poor class separation is visible." title="Projection of the last MLP hidden layer activations before training, SVHN test subset"><br></center><br><center><br><img src="/img/vis-2016-netural-network/svhn_after_training_projection.png" alt="图4 Projection of the MLP hidden layer activations after training, SVHN test subset. a) First hidden layer (NH: 52.78%). b) Last hidden layer (NH: 67%)." title="Projection of the MLP hidden layer activations after training, SVHN test subset"><br></center><br>相比于MNIST这个数据集，SVHN直接降维后类别的区分度要差很多。如图3所示，NH值仅20.94%。图4展示的MLP第一层数据表示和最后一层数据表示之间的区别。主要为了说明神经网络随着层数的加深，是否可以学到更高的特征表示。从图4中我们可以看出，最后一层确实学到了更好的有利于分类的特征。作者还发现最后一层的降维结果中，每个类别被分成了两个cluster。通过分析发现，一个是相同数字包含亮背景一个是暗背景。然后作者通过高斯模糊对输入图像进行处理，提高了分类的准确率。同时，作者用相同的方式分析了CNN的结果。<br><br>对于如何展示特征表示的演化，作者采用2D的轨迹来表示序列，相比于动画而言更容易捕捉变化。并采用trail bundling避免拥堵混乱。如图5所示，展示了神经网络不同层之间特征表示的演变。图6表示迭代过程中，最后一层隐藏层的演变。<br><center><br><img src="/img/vis-2016-netural-network/mnist_inter_layer_evolution.png" alt="图5 Inter-layer evolution, four MLP hidden layers after training, MNIST test subset. Brighter trail parts show later layers." title="Inter-layer evolution, four MLP hidden layers after training, MNIST test subset."><br></center><br><center><br><img src="/img/vis-2016-netural-network/mnist_inter_epoch_evolution.png" alt="图6 Inter-epoch evolution, last CNN hidden layer, epochs 0-100, in steps of 20, MNIST test subset. Brighter trail parts show later epochs." title="Inter-epoch evolution, last CNN hidden layer, epochs 0-100, in steps of 20, MNIST test subset. ">&lt;<br></center>

<p>对于神经元之间的关系可视化，作者通过计算神经元的相似性，并通过MDS投影进行展示。计算相似性采用计算神经元在数据集上的empirical (Pearson’s) correlation coefficien。由于t-SNE在于保持局部邻接结构，而MDS会保存全局结构。所以这里选择MDS。</p>
<center><br><img src="/img/vis-2016-netural-network/mnist_activation_neuron_projection.png" alt="图7 Activation and neuron projections of last CNN hidden layer activations before and after training, MNIST test subset. Neuron projection colors show the neurons’ power to discriminate class 8 vs rest." title="Activation and neuron projections of last CNN hidden layer activations before and after training, MNIST test subset."><br></center><br>图7c展示了训练后的激励投影，图7d展示了相应的神经元投影。然后作者根据区分类别的能力对神经元进行着色。图7展示了神经元区分class 8的能力。在训练前，区分能力在神经元中比较分散，而训练后，区分class 8的神经元在左下角的那一块。对于其他class也有相似的结论。<br><center><br><img src="/img/vis-2016-netural-network/svhn_neuron_map.png" alt="图8 Discriminative neuron map of last CNN hidden layer activations after training, SVHN test subset." title="Discriminative neuron map of last CNN hidden layer activations after training, SVHN test subset."><br></center><br><center><br><img src="/img/vis-2016-netural-network/svhn_activation_projection.png" alt="图9 Activation projection of the last CNN hidden layer after training, SVHN test subset. Color shows the activation of neuron 460, highly associated to class 3." title="Activation projection of the last CNN hidden layer after training, SVHN test subset."><br></center><br>图8展示了各个神经元区别class的能力。颜色根据区别classes能力的最大值而定。从中可以看出，我们可以根据class的类别对神经元进行分类。这些神经元基本都聚集在一起。而图9展示了CNN最后一层hidden layer的投影，颜色展示了neuron 460的激励值。而neuron 460是与class 3相关。从图中我们发现被着色的有两个cluster。其中一个是在亮背景下的数字3，另一个是在亮背景下的数字5。<br><br>本文使用降维的方法对神经网络进行可视化。但是降维投影有其缺陷。首先，对于大量的数据可能非常耗时，甚于无法投影。而且可能会出现重叠现象。对于不同的参数或者初始值，可能得到不同的降维结果。<br><br>## Towards Better Analysis of Deep Convolutional Neural Networks<br>刘世霞老师的这篇论文[1]相较于前一篇文章，使用了更加复杂的神经网络，并且很好的继承了之前机器学习领域人员所做的相关可视化工作。对于图像卷积神经网络的可视化主要可以分成两类：code inversion 和 activation maximization。code inversion是指当一个图像通过卷积神经网络时，可以得到神经网络各层convnet的激励值。对于一个全连接的神经网络，神经元的顺序是没有意思的，然后对于卷积神经网络，连接关系是根据原始图像的2D卷积定义的。因此，由卷积产生的各层的激励在空间上是位置相关的。所以，对于每个图像，我们可以得到各层各个channel卷积产生的灰度图。同时我们可以通过deconv得到相应的图像特征。activation maximization是为了找到一个图像，它可以使某个指定的神经元的激励达到最大。根据这两种方法，Yosinski等人[2]实现了一个系统，它提供了两个工具，分别对应上述两个方法。Yosinski使用的是AlexNet，如图10所示。<br><br><center><img src="/img/vis-2016-netural-network/alexnet1.png" alt="" title="AlexNet structure"> <img src="/img/vis-2016-netural-network/alexnet2.png" alt="图10 AlexNet卷积神经网络结构" title="AlexNet structure"></center>

<p>AlexNet包含了7层隐藏层，其中第一二五层是卷积Conv加上Pool,三四层是单独的卷积层，最后六七层是一个全连接神经网络。</p>
<center><img src="/img/vis-2016-netural-network/y_system_overview.png" alt="图11 Yosinski的系统概览" title="Yosinski system overview"></center>

<center><img src="/img/vis-2016-netural-network/activations_151_1.png" alt="" title="activations of the 151st channel on the conv5 layer"> <img src="/img/vis-2016-netural-network/activations_151_2.png" alt="图12 第conv5层第151个channel的激励" title="activations of the 151st channel on the conv5 layer"></center><br>图12中展示了AlexNet的conv5层中第151个channel在不同图片上的激励。可以明显地发现该channel对人脸及动物脸部会产生较高的激励。同时，对激励进行deconv可以得到该神经元识别的特征。如图11所示，摄像头输入了猫脸的图像，所选的conv5中的151st channel很好得识别了猫脸的位置，并且从解卷积后的图像可以明显得看出猫脸的特征。右边一栏展示了训练集中在该激励上相似的top9图像，并展示了相应的解卷积结果。<br><br>第二种方法是activation maximization，通过优化方法来找到使某个神经元达到最大的图像激励，通常需要加入正则化项来矫正图像。首先输入一张图片，它在某个神经元上会引起一个激励，然后根据梯度优化得到使该神经元达到最大值的输入：<br><center><img src="/img/vis-2016-netural-network/activation_max.png" alt="" title="activation optimization equation"></center><br>x表示输入图像，x*表示优化后得到的结果图像。a_i(x)表示单元i在图像x上的激励，R_theta(x)表示正则化项。正则化方法有以下几种：<br><br>- L2 decay<br>- Gaussian blur<br>- Clipping pixels with small norm<br>- Clipping pixels with small contribution<br><br><center><img src="/img/vis-2016-netural-network/activation_max_unit.png" alt="图13 不同layer fc8不同类别单元期望的输入的可视化" title="Visualizations of the preferred inputs for different class units on layer fc8"></center>

<p>而刘世霞老师的这篇文章中的图像特征是采用第一种方法code inversion。记录输入数据集在相应neuron上产生的激励矩阵和相应的top5特征图像块。对于整个神经网络采用DAG图的形式进行可视化。系统概览如图14所示。</p>
<p><center><img src="/img/vis-2016-netural-network/cnnvis_system.png" alt="图14 CNNVis系统概览" title="CNNVis system overview"></center><br>于之前的文章不同，该系统展示了整个神经网络的结构和各个神经元之间的关系。为了有效得表示大型的CNN网络，文章中作者对layers和neurons进行了聚类。layers在每个pooling layer进行划分，分成若干个groups。每一层的neurons根据训练集在不同class上的平均激励值进行聚类。最后每个cluster被表示成DAG图中的节点。图中每个neruon cluster节点被表示成矩阵。矩阵中显示训练得到的特征，神经元激励值或者对最后结果的贡献值。这里学习得到的特征被表示成小矩阵，通过rectangle packing算法布局在neuron cluster矩阵中。为了减少图中边的可视混乱问题，作者提出了biclustering-based边绑定算法，将权值相近的边绑定在一起。除了可以展示神经元学习得到的特征外，作者还提出了以矩阵的形式展示cluster中神经元的激励在各个类别上的分布。具体的可视化流程如图15所示：</p>
<p><center><img src="/img/vis-2016-netural-network/cnnvis_pipeline.png" alt="图15 CNNVis系统流程" title="CNNVis pipeline"></center><br>对于rectangle packing算法布局，biclustering-based边绑定算法， activation matrix reordering算法，以及neurons聚类算法的具体内容请参考论文。这里不同详细描述。对于论文的有效性，作者通过2个case study加以证明。一个是对不同深度，宽度的CNN的可视化探索比较，用来说明CNNVis对于帮助机器学习专家对CNN结构的改进的帮助性，另一个是训练诊断，对于改进后的CNN网络无法达到预期结果时，如何通过CNNVis进行诊断发现问题所在，并对模型进行改进（具体内容详见论文）。</p>
<h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>以上是今年的两篇关于神经网络的可视化论文。神经网络现在在图像领域已经火的不行，现在的视觉论文基本都是神经网络为主。最近几年开始想NLP领域发展。对于可视化这块，感觉无论是科学计算可视化还是信息可视化，在神经网络这块，都有很多工作可以做。明天的VIS应该会出现更多这方面的论文。</p>
<p>[1] Liu, M., Shi, J., Li, Z., Li, C., Zhu, J., &amp; Liu, S. (2016). Towards Better Analysis of Deep Convolutional Neural Networks, 2626(c). <a href="http://doi.org/10.1109/TVCG.2016.2598831" target="_blank" rel="external">http://doi.org/10.1109/TVCG.2016.2598831</a><br>[2] Yosinski, J., Clune, J., &amp; Fuchs, T. (2015). Understanding Neural Networks Through Deep Visualization.<br>[3] Telea, A. C., Rauber, P. E., Fadel, S. G., &amp; Falc, A. X. (2016). Visualizing the Hidden Activity of Artificial Neural Networks, 1(c). <a href="http://doi.org/10.1109/TVCG.2016.2598838" target="_blank" rel="external">http://doi.org/10.1109/TVCG.2016.2598838</a>  </p>

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/vis2016/" rel="tag">#vis2016</a>
          
            <a href="/tags/netural-network/" rel="tag">#netural network</a>
          
            <a href="/tags/visualization/" rel="tag">#visualization</a>
          
            <a href="/tags/research/" rel="tag">#research</a>
          
        </div>
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2016/09/18/hello-world/" rel="next" title="Hello World">
                <i class="fa fa-chevron-left"></i> Hello World
              </a>
            
          </div>

          <div class="post-nav-prev post-nav-item">
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
        <!-- JiaThis Button BEGIN -->
<div class="jiathis_style">
  <a class="jiathis_button_tsina"></a>
  <a class="jiathis_button_tqq"></a>
  <a class="jiathis_button_weixin"></a>
  <a class="jiathis_button_cqq"></a>
  <a class="jiathis_button_douban"></a>
  <a class="jiathis_button_renren"></a>
  <a class="jiathis_button_qzone"></a>
  <a class="jiathis_button_kaixin001"></a>
  <a class="jiathis_button_copy"></a>
  <a href="http://www.jiathis.com/share" class="jiathis jiathis_txt jiathis_separator jtico jtico_jiathis" target="_blank"></a>
  <a class="jiathis_counter_style"></a>
</div>
<script type="text/javascript" >
  var jiathis_config={
    hideMore:false
  }
</script>
<script type="text/javascript" src="http://v3.jiathis.com/code/jia.js" charset="utf-8"></script>
<!-- JiaThis Button END -->

      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
      <div class="ds-thread" data-thread-key="2016/09/28/vis-2016-netural-network/"
           data-title="人工神经网络可视化--2016年可视化会议" data-url="http://yanyuyu.info/2016/09/28/vis-2016-netural-network/">
      </div>
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel ">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/uploads/avatar.jpg"
               alt="Ivan" />
          <p class="site-author-name" itemprop="name">Ivan</p>
          <p class="site-description motion-element" itemprop="description">学习总结 思考感悟 知识管理</p>
        </div>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/archives">
              <span class="site-state-item-count">2</span>
              <span class="site-state-item-name">日志</span>
            </a>
          </div>

          
            <div class="site-state-item site-state-categories">
              <a href="/categories">
                <span class="site-state-item-count">1</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            <div class="site-state-item site-state-tags">
              <a href="/tags">
                <span class="site-state-item-count">4</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        
          <div class="feed-link motion-element">
            <a href="/atom.xml" rel="alternate">
              <i class="fa fa-rss"></i>
              RSS
            </a>
          </div>
        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://www.zhihu.com/people/Ivan0131" target="_blank" title="zhihu">
                  
                    <i class="fa fa-fw fa-globe"></i>
                  
                  zhihu
                </a>
              </span>
            
          
        </div>

        
        
          <div class="cc-license motion-element" itemprop="license">
            <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" target="_blank">
              <img src="/images/cc-by-nc-sa.svg" alt="Creative Commons" />
            </a>
          </div>
        

        
        

      </section>

      
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">
            
              
            
            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Visualizing-the-Hidden-Activity-of-Artificial-Neural-Networks"><span class="nav-number">1.</span> <span class="nav-text">Visualizing the Hidden Activity of Artificial Neural Networks</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#结论"><span class="nav-number">2.</span> <span class="nav-text">结论</span></a></li></ol></div>
            
          </div>
        </section>
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2016</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Ivan</span>
</div>

<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Mist
  </a>
</div>

        

        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  



  
  <script type="text/javascript" src="/vendors/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/vendors/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/vendors/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/vendors/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/vendors/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/vendors/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.0.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.0.1"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.0.1"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.0.1"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.0.1"></script>



  

  
    
  

  <script type="text/javascript">
    var duoshuoQuery = {short_name:"yanyuyu"};
    (function() {
      var ds = document.createElement('script');
      ds.type = 'text/javascript';ds.async = true;
      ds.id = 'duoshuo-script';
      ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
      ds.charset = 'UTF-8';
      (document.getElementsByTagName('head')[0]
      || document.getElementsByTagName('body')[0]).appendChild(ds);
    })();
  </script>

  
    
    <script src="/vendors/ua-parser-js/dist/ua-parser.min.js?v=0.7.9"></script>
    <script src="/js/src/hook-duoshuo.js"></script>
  






  
  

  

  

  

</body>
</html>
